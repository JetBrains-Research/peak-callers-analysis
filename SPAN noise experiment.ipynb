{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SPAN noise experiment\n",
    "\n",
    "Logbook: https://docs.google.com/document/d/10ItWypr53n7GlS-XKvvR7WteSpdjgUdBeMAFBoFj00k/edit#heading=h.15aayc8a5f19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:12.254230Z",
     "start_time": "2019-03-07T11:38:04.952806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os, re\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import subprocess, tempfile\n",
    "from pathlib import Path\n",
    "import downstream.bed_metrics as bm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '/mnt/stripe/shpynov/span-noise-experiment'\n",
    "MODIFICATIONS = ['H3K27ac' , 'H3K27me3', 'H3K36me3', 'H3K4me3', 'H3K4me1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:48.419134Z",
     "start_time": "2019-03-07T11:38:12.260987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MACS2_LEVELS = ['q1e-10', 'q1e-6', 'broad0.1', 'q0.05', 'q0.1', 'q0.2', 'q0.5']\n",
    "\n",
    "dfm = pd.DataFrame(columns=['modification', 'alpha', 'replicate', 'level', 'file', 'peaks', 'length'])\n",
    "for modification in MODIFICATIONS:\n",
    "    print(modification)\n",
    "    for file in tqdm(glob.glob(os.path.join(FOLDER, modification, 'macs2', '*.*Peak'))):\n",
    "        if file.endswith('gappedPeak'):\n",
    "            continue\n",
    "        level = next((l for l in MACS2_LEVELS if f'_{l}' in file), None) # \n",
    "        if level:\n",
    "            alpha = re.sub('.*hg19_|_[0-9]_[qb].*', '', os.path.basename(file))\n",
    "            replicate = re.sub('.*hg19_[0-9\\.]+_|_[qb].*', '', os.path.basename(file))\n",
    "            out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "            if out[0].strip() != '':\n",
    "                peaks, length = out[0].split(' ') \n",
    "            else:\n",
    "                peaks, length = 0, 0\n",
    "            dfm.loc[len(dfm)] = (modification, alpha, replicate, f'macs2 {level}', file, peaks, length)\n",
    "        \n",
    "# Fix types\n",
    "dfm['peaks'] = dfm['peaks'].astype(int)\n",
    "dfm['length'] = dfm['length'].astype(int)\n",
    "# Sort\n",
    "dfm.sort_values(by=['modification', 'alpha', 'level', 'replicate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show(df, exp=False):\n",
    "    dft = df.loc[df['alpha'].astype(float) <= 9].copy()\n",
    "    dft['ma'] = dft['modification'] + '_' + dft['alpha']\n",
    "    df_mean = dft.groupby(['ma', 'level'])['peaks'].mean().reset_index().sort_values(by=['ma', 'level'])\n",
    "    df_std = dft.groupby(['ma', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['ma', 'level'])\n",
    "\n",
    "    fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "    for l in sorted(set(df_mean['level'])):\n",
    "        dfml = df_mean.loc[df_mean['level']==l]\n",
    "        dfsl = df_std.loc[df_std['level']==l]\n",
    "        fig.add_trace(go.Scatter(x=dfml['ma'], y=dfml['peaks'], name=f\"{l} mean\", line_shape='linear'))\n",
    "        fig.add_trace(go.Scatter(x=dfsl['ma'], y=dfsl['peaks'], name=f\"{l} std\", line_shape='linear', \n",
    "                                 line=dict(dash='dot')))\n",
    "    if exp:\n",
    "        fig.update_layout(yaxis_type=\"log\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SICER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SICER_LEVELS = ['FDR0.5', 'FDR0.2', 'FDR0.1', 'FDR0.05', 'FDR0.01', 'FDR1e-6', 'FDR1e-10']\n",
    "\n",
    "dfsc = pd.DataFrame(columns=['modification', 'alpha', 'replicate', 'level', 'file', 'peaks', 'length'])\n",
    "for modification in MODIFICATIONS:\n",
    "    print(modification)\n",
    "    for file in tqdm(glob.glob(os.path.join(FOLDER, modification, 'sicer', '*-FDR*'))):\n",
    "        level = next((l for l in SICER_LEVELS if f'-{l}' in file), None) # \n",
    "        if level:\n",
    "            alpha = re.sub('.*hg19_|_[0-9]-W.*', '', os.path.basename(file))\n",
    "            replicate = re.sub('.*hg19_[0-9\\.]+_|-W.*', '', os.path.basename(file))\n",
    "            out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "            if out[0].strip() != '':\n",
    "                peaks, length = out[0].split(' ') \n",
    "            else:\n",
    "                peaks, length = 0, 0\n",
    "            dfsc.loc[len(dfsc)] = (modification, alpha, replicate, f'sicer {level}', file, peaks, length)\n",
    "# Fix types\n",
    "dfsc['peaks'] = dfsc['peaks'].astype(int)\n",
    "dfsc['length'] = dfsc['length'].astype(int)\n",
    "# Sort\n",
    "dfsc.sort_values(by=['modification', 'alpha', 'level', 'replicate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dfsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAN_LEVELS = ['0.5', '0.2', '0.1', '0.05', '0.01', '1E-6', '1E-10', 'tuned']\n",
    "\n",
    "dfsp = pd.DataFrame(columns=['modification', 'alpha', 'replicate', 'level', 'file', 'peaks', 'length'])\n",
    "for modification in MODIFICATIONS:\n",
    "    print(modification)\n",
    "    for file in tqdm(glob.glob(os.path.join(FOLDER, modification, 'span', '*.peak'))):\n",
    "        level = next((l for l in SPAN_LEVELS if f'_{l}' in file), None) # \n",
    "        if level:\n",
    "            alpha = re.sub('.*hg19_|_[0-9]_200.*', '', os.path.basename(file))\n",
    "            replicate = re.sub('.*hg19_[0-9\\.]+_|_200.*', '', os.path.basename(file))\n",
    "            out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "            if out[0].strip() != '':\n",
    "                peaks, length = out[0].split(' ') \n",
    "            else:\n",
    "                peaks, length = 0, 0\n",
    "            dfsp.loc[len(dfsp)] = (modification, alpha, replicate, f'span {level}', file, peaks, length)\n",
    "# Fix types\n",
    "dfsp['peaks'] = dfsp['peaks'].astype(int)\n",
    "dfsp['length'] = dfsp['length'].astype(int)\n",
    "# Sort\n",
    "dfsp.sort_values(by=['modification', 'alpha', 'level', 'replicate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dfsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAN replicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspr = pd.DataFrame(columns=['modification', 'alpha', 'replicate', 'level', 'file', 'peaks', 'length'])\n",
    "for modification in MODIFICATIONS:\n",
    "    print(modification)\n",
    "    for file in tqdm(glob.glob(os.path.join(FOLDER, modification, 'span_rep', '*.peak'))):\n",
    "        level = next((l for l in SPAN_LEVELS if f'_{l}' in file), None) # \n",
    "        if level:\n",
    "            alpha = re.sub('.*hg19_|_200.*', '', os.path.basename(file))\n",
    "            out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "            if out[0].strip() != '':\n",
    "                peaks, length = out[0].split(' ') \n",
    "            else:\n",
    "                peaks, length = 0, 0\n",
    "            dfspr.loc[len(dfspr)] = (modification, alpha, 'None', f'span rep {level}', file, peaks, length)\n",
    "# Fix types\n",
    "dfspr['peaks'] = dfspr['peaks'].astype(int)\n",
    "dfspr['length'] = dfspr['length'].astype(int)\n",
    "# Sort\n",
    "dfspr.sort_values(by=['modification', 'alpha', 'level'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dfspr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.concat([dfm, dfsc, dfsp, dfspr])\n",
    "dfa.sort_values(by=['modification', 'alpha', 'level'], inplace=True)\n",
    "dfa = dfa.loc[dfa['alpha'].astype(float) <= 9]\n",
    "display(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dfa)\n",
    "# dfa['ma'] = dfa['modification'] + '_' + dfa['alpha']\n",
    "# dfa_mean = dfa.groupby(['ma', 'level'])['peaks'].mean().reset_index().sort_values(by=['ma', 'level'])\n",
    "# dfa_std = dfa.groupby(['ma', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['ma', 'level'])\n",
    "\n",
    "# fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "# for l in sorted(set(dfa_mean['level'])):\n",
    "#     fig.add_trace(go.Scatter(x=dfa_mean.loc[dfa_mean['level']==l]['ma'], \n",
    "#                              y=dfa_mean.loc[dfa_mean['level']==l]['peaks'], \n",
    "#                              name=f\"{l} mean\", line_shape='linear'))\n",
    "#     fig.add_trace(go.Scatter(x=dfa_std.loc[dfa_std['level']==l]['ma'], \n",
    "#                              y=dfa_std.loc[dfa_std['level']==l]['peaks'], \n",
    "#                              name=f\"{l} std\", line_shape='linear', \n",
    "#                              line=dict(dash='dot')))\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['avg_length'] = dfa['length'] / dfa['peaks']\n",
    "dfa.loc[~np.isfinite(dfa[\"avg_length\"]), \"avg_length\"] = 0.0\n",
    "dfa['ma'] = dfa['modification'] + '_' + dfa['alpha']\n",
    "\n",
    "dfa_mean = dfa.groupby(['ma', 'level'])['avg_length'].mean().reset_index().sort_values(by=['ma', 'level'])\n",
    "dfa_std = dfa.groupby(['ma', 'level'])['avg_length'].std().reset_index().fillna(0).sort_values(by=['ma', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Average length\")))\n",
    "for l in sorted(set(dfa_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfa_mean.loc[dfa_mean['level']==l]['ma'], \n",
    "                             y=dfa_mean.loc[dfa_mean['level']==l]['avg_length'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfa_std.loc[dfa_std['level']==l]['ma'], \n",
    "                             y=dfa_std.loc[dfa_std['level']==l]['avg_length'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision / Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfpr = pd.DataFrame(columns=['modification', 'replicate', 'level', 'alpha', 'precision', 'recall'])\n",
    "mlrs = dfa['modification'] + '_' + dfa['level'] + '_' + dfa['replicate']\n",
    "for m in tqdm(set(mlrs)):\n",
    "    dfmlrs = dfa.loc[mlrs == m]\n",
    "    modification = dfmlrs.iloc[0]['modification']\n",
    "    level = dfmlrs.iloc[0]['level']\n",
    "    alpha = dfmlrs.iloc[0]['replicate']\n",
    "    alpha0 = dfmlrs.loc[dfmlrs['alpha'].astype(float) == 0]\n",
    "    for _, r in dfmlrs.loc[dfmlrs['alpha'].astype(float) > 0].iterrows():        \n",
    "        alpha_other = r['alpha']\n",
    "        paths = [Path(alpha0.iloc[0]['file']), Path(r['file'])] \n",
    "        df_path = f'/tmp/pr_{m}_{alpha_other}.tsv'\n",
    "        mt = bm.load_or_build_metrics_table(paths, paths, Path(df_path), jaccard=False, threads=30)\n",
    "        precision, recall = mt.iloc[1, 0], mt.iloc[0, 1]\n",
    "        dfpr.loc[len(dfpr)] = (modification, replicate, level, alpha_other, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for m in MODIFICATIONS:\n",
    "#     print(m)\n",
    "#     dfmod = dfpr.loc[dfpr['modification'] == m]\n",
    "#     dfprecision = dfmod.groupby(['alpha', 'level'])['precision'].mean().reset_index().sort_values(\n",
    "#         by=['alpha', 'level'], ascending=False)\n",
    "#     dfprecision['al'] = dfprecision['alpha'] + '_' + dfprecision['level']\n",
    "#     dfrecall = dfmod.groupby(['alpha', 'level'])['recall'].mean().reset_index().sort_values(\n",
    "#         by=['alpha', 'level'], ascending=False)\n",
    "#     dfrecall['al'] = dfrecall['alpha'] + '_' + dfrecall['level']\n",
    "    \n",
    "#     dfprecisionrecall = pd.merge(on='al', left=dfprecision, right=dfrecall).sort_values(\n",
    "#         by=['alpha_x', 'level_x'])\n",
    "# #     display(dfprecisionrecall)\n",
    "\n",
    "#     fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"\")))\n",
    "#     for l in sorted(set(dfprecisionrecall['level_x'])):\n",
    "#         dfprl = dfprecisionrecall.loc[dfprecisionrecall['level_x']==l]\n",
    "#         fig.add_trace(go.Scatter(x=dfprl['recall'], \n",
    "#                                  y=dfprl['precision'],\n",
    "#                                  name=f\"{l} precision vs recall\", line_shape='linear'))\n",
    "#     # fig.update_layout(yaxis_type=\"log\")\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in MODIFICATIONS:\n",
    "    print(m)\n",
    "    dfmod = dfpr.loc[dfpr['modification'] == m]\n",
    "    dfprecision = dfmod.groupby(['alpha', 'level'])['precision'].mean().reset_index().sort_values(\n",
    "        by=['alpha', 'level'], ascending=False)\n",
    "    dfrecall = dfmod.groupby(['alpha', 'level'])['recall'].mean().reset_index().sort_values(\n",
    "        by=['alpha', 'level'], ascending=False)\n",
    "\n",
    "    fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"\")))\n",
    "    for l in sorted(set(dfprecision['level'])):\n",
    "        fig.add_trace(go.Scatter(x=dfprecision.loc[dfprecision['level']==l]['alpha'], \n",
    "                                 y=dfprecision.loc[dfprecision['level']==l]['precision'], \n",
    "                                 name=f\"{l} precision\", line_shape='linear'))\n",
    "        fig.add_trace(go.Scatter(x=dfrecall.loc[dfrecall['level']==l]['alpha'], \n",
    "                                 y=dfrecall.loc[dfrecall['level']==l]['recall'], \n",
    "                                 name=f\"{l} recall\", line_shape='linear', \n",
    "                                 line=dict(dash='dot')))\n",
    "    # fig.update_layout(yaxis_type=\"log\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute overlaps per modification, alpha, level\n",
    "\n",
    "dfo = pd.DataFrame(columns=['id', 'modification', 'alpha', 'level', 'overlap'])\n",
    "mals = dfa['modification'] + '_' + dfa['alpha'] + '_' + dfa['level']\n",
    "for m in tqdm(sorted(set(mals))):\n",
    "    dfmod = dfa.loc[mals == m]\n",
    "    modification = dfmod.iloc[0]['modification']\n",
    "    alpha = dfmod.iloc[0]['alpha']\n",
    "    level = dfmod.iloc[0]['level']\n",
    "    paths = [Path(f) for f in dfmod['file']] \n",
    "    df_path = f'/tmp/overlap_{m}.tsv'\n",
    "    mt = bm.load_or_build_metrics_table(paths, paths, Path(df_path),\n",
    "                                        jaccard=False,\n",
    "                                        threads=30)\n",
    "    for row in mt.index:\n",
    "        for col in mt.columns:\n",
    "            overlap = mt.loc[row][col]\n",
    "            dfo.loc[len(dfo)] = (f'{row}@{col}', modification, alpha, level, overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap plots values with split by modification and alpha\n",
    "sizex = len(sorted(set(dfo['level'])))\n",
    "for m in MODIFICATIONS:\n",
    "    print(m)\n",
    "    fig = plt.figure(figsize=(int(sizex * 4), 4))\n",
    "    data = dfo.loc[dfo['modification'] == m]\n",
    "    ax = plt.axes()\n",
    "    sns.barplot(data=data, \n",
    "                x='alpha', y='overlap', hue='level',\n",
    "                ci=\"sd\", capsize=.2, errwidth=2,\n",
    "                edgecolor=\"black\",\n",
    "                ax = ax)\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overlaps per modification, level\n",
    "dfo = pd.DataFrame(columns=['id', 'modification', 'level', 'overlap'])\n",
    "mls = dfa['modification'] + '_' + dfa['level']\n",
    "for m in tqdm(sorted(set(mls))):\n",
    "    dfmod = dfa.loc[mls == m]\n",
    "    modification = dfmod.iloc[0]['modification']\n",
    "    level = dfmod.iloc[0]['level']\n",
    "    paths = [Path(f) for f in dfmod['file']] \n",
    "    df_path = f'/tmp/overlap_{m}.tsv'\n",
    "    mt = bm.load_or_build_metrics_table(paths, paths, Path(df_path),\n",
    "                                        jaccard=False,\n",
    "                                        threads=30)\n",
    "    for row in mt.index:\n",
    "        for col in mt.columns:\n",
    "            overlap = mt.loc[row][col]\n",
    "            dfo.loc[len(dfo)] = (f'{row}@{col}', modification, level, overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap plots values with split by modification and alpha\n",
    "sizex = len(sorted(set(dfo['level'])))\n",
    "for m in MODIFICATIONS:\n",
    "    print(m)\n",
    "    fig = plt.figure(figsize=(int(sizex * 4), 4))\n",
    "    data = dfo.loc[dfo['modification'] == m]\n",
    "    ax = plt.axes()\n",
    "    sns.barplot(data=data, \n",
    "                x='level', y='overlap',\n",
    "                ci=\"sd\", capsize=.2, errwidth=2,\n",
    "                edgecolor=\"black\",\n",
    "                ax = ax)\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak significance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "levels = ['macs2 q0.05', 'sicer FDR0.05', 'span 0.05']\n",
    "for l in levels:\n",
    "    tl = dfa.loc[dfa['level'] == l]\n",
    "    for m in sorted(set(dfm['modification'])):\n",
    "#         print(m, level)\n",
    "        t = tl.loc[tl['modification'] == m]\n",
    "        t = t.loc[t['replicate'] == '0']\n",
    "        t = t.loc[t['alpha'].astype(float) <= 9]\n",
    "        t = t.loc[t['peaks'].astype(int) > 0]\n",
    "        hist_data = []\n",
    "        alphas = []\n",
    "        for i, row in tqdm(t.iterrows()):\n",
    "            if 'macs2' in l:\n",
    "                pdf = pd.read_csv(row['file'], sep='\\t', \n",
    "                                  names=['chr', 'start', 'end', 'name', 'score', 'strand', 'fc', 'p', 'q'])\n",
    "                mlqs = pdf['q']\n",
    "            elif 'sicer' in l:\n",
    "                pdf = pd.read_csv(row['file'], sep='\\t', \n",
    "                                  names=['chr', 'start', 'end', 'reads', 'creads', 'p', 'fc', 'q'])\n",
    "                qs = -np.log10(pdf['q'])\n",
    "                mlqs = np.where(~np.isfinite(qs), 1000, qs) # 300 is empirical max for SICER\n",
    "            elif 'span' in l:\n",
    "                pdf = pd.read_csv(row['file'], sep='\\t', \n",
    "                                  names=['chr', 'start', 'end', 'name', 'score', 'strand', 'fc', 'p', 'q'])\n",
    "                mlqs = pdf['q']                \n",
    "            else:\n",
    "                raise Exception(f'Unknow level {l}')                \n",
    "                \n",
    "            hist_data.append(np.where(mlqs > 1000, 1000, mlqs))\n",
    "            alphas.append(row['alpha'])\n",
    "\n",
    "        # Create distplot with curve_type set to 'normal'\n",
    "        fig = ff.create_distplot(hist_data, alphas, show_hist=False, show_rug=False)\n",
    "\n",
    "        # Add title\n",
    "        fig.update_layout(title_text=f'Minus log q-value distribution {l} {m}')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
