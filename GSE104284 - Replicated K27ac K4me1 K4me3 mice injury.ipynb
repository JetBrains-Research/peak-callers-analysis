{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GSE104284 - Replicated K27ac K4me1 K4me3 mice injury\n",
    "\n",
    "Logbook: https://docs.google.com/document/d/1vxU3bRWPjKhz4yto3eOQxKDNQQu0xsyi9IUCSsWBS9k/edit#heading=h.44kd47qfiiva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:12.254230Z",
     "start_time": "2019-03-07T11:38:04.952806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os, re\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import subprocess, tempfile\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here and there < 5mln reads\n",
    "UNDER_5MLN_TRACKS = [\n",
    "    'GSM2794025_3h_03_Right_B_K27ac_C36PAACXX.8',  \n",
    "                   'GSM2794037_3h_11_Right_K27ac_C36PAACXX.8',\n",
    "                  'GSM2794038_3h_11_Right_K4me1_C36PAACXX.8',\n",
    "                  'GSM2794039_3h_11_Right_K4me3_C36PAACXX.8',\n",
    "                  'GSM2794040_3h_11_Right_Input_C36PAACXX.8',\n",
    "                  'GSM2794042_3h_11_Left_K4me1_C36PAACXX.8',\n",
    "                  'GSM2794044_3h_12_Right_K27ac_C36PAACXX.7',\n",
    "                  'GSM2794045_3h_12_Right_K4me1_C36PAACXX.7',\n",
    "                  'GSM2794046_3h_12_Right_K4me3_C36PAACXX.7',\n",
    "                  'GSM2794047_3h_12_Left_K27ac_C36PAACXX.7',\n",
    "                  'GSM2794048_3h_12_Left_K4me1_C36PAACXX.7',\n",
    "                  'GSM2794049_3h_12_Left_K4me3_C36PAACXX.7',\n",
    "                  'GSM2794072_C4KGFACXX.1.10hr_06_Right_K4me3',\n",
    "                  'GSM2794086_C36UVACXX.3.24hr_02_Left_K27ac',\n",
    "                  'GSM2794205_C3A8DACXX140504.1.7d_02_Right_K27ac',\n",
    "                  'GSM2794214_C3A8DACXX140504.5.7d_03_Right_K4me1',\n",
    "                   'GSM2794222_C3A8DACXX140504.7.7d_04_Right_K4me3',\n",
    "                   'GSM2794225_C3A8DACXX140504.8.7d_04_Right_K4me3',\n",
    "                   'GSM2794235_C3A8DACXX140504.7.7d_04B_Right_K27ac',\n",
    "                   'GSM2794239_C3A8DACXX140504.8.7d_04B_Right_K27ac',\n",
    "                   'GSM2794244_C3A8DACXX140504.7.7d_04B_Left_K4me1',\n",
    "                   'GSM2794245_C3A8DACXX140504.7.7d_04B_Left_K4me3',\n",
    "                   'GSM2794248_C3A8DACXX140504.8.7d_04B_Left_K4me1',\n",
    "                   'GSM2794249_C3A8DACXX140504.8.7d_04B_Left_K4me3',\n",
    "                   'GSM2794280_C4KGFACXX.8.14d_04_Right_K4me1',\n",
    "                   'GSM2794288_C4KGFACXX.8.14d_05_Right_K4me3',\n",
    "                  ]\n",
    "\n",
    "def ok(f):\n",
    "    for bt in UNDER_5MLN_TRACKS:\n",
    "        if bt in f:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloaded GEO peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_FOLDER='/mnt/stripe/bio/raw-data/geo-samples/GSE104284/geo'\n",
    "\n",
    "dfg = pd.DataFrame(columns=['gsm', 'time', 'direction', 'modification', 'replicate', \n",
    "                            'level', 'file', 'peaks', 'length'])\n",
    "for file in tqdm(glob.glob(GEO_FOLDER + '/*.*')):\n",
    "    if 'Input' in file or not ok(file):\n",
    "        continue\n",
    "    gsm = re.sub('_.*', '', os.path.basename(file))\n",
    "    time = re.sub(f'(.*Aguilar_)|(_[0-9a-zA-Z]+_.*)', '', os.path.basename(file))\n",
    "    direction = next((d for d in ['Left', 'Right'] if d in os.path.basename(file)), None)\n",
    "    modification = next((m for m in ['K4me1', 'K4me3', 'K27ac'] if m in os.path.basename(file)), None)        \n",
    "    replicate = re.sub(f'(.*{time}_)|(_{direction}.*)', '', os.path.basename(file))\n",
    "    out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "    if out[0].strip() != '':\n",
    "        peaks, length = out[0].split(' ') \n",
    "    else:\n",
    "        peaks, length = 0, 0\n",
    "    dfg.loc[len(dfg)] = (gsm, time, direction, modification, replicate, 'geo', file, peaks, length)\n",
    "\n",
    "# display(dfg.head())    \n",
    "    \n",
    "dfg['timesrt'] = [\"{:0>3d}\".format(int(re.match('[0-9]+', t)[0]) * 24) if \n",
    "                   t.endswith('d') else \"{:0>3d}\".format(int(re.match('[0-9]+', t)[0])) \n",
    "                  for t in dfg['time'] ]\n",
    "        \n",
    "# Fix types\n",
    "dfg['peaks'] = dfg['peaks'].astype(int)\n",
    "dfg['length'] = dfg['length'].astype(int)\n",
    "\n",
    "geo_gsms = set(dfg['gsm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg['mdt'] = dfg['modification'] + '_' + dfg['direction'] + '_' + dfg['timesrt']\n",
    "dfg_mean = dfg.groupby(['mdt', 'level'])['peaks'].mean().reset_index().sort_values(by=['mdt', 'level'])\n",
    "dfg_std = dfg.groupby(['mdt', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['mdt', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfg_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfg_mean.loc[dfg_mean['level']==l]['mdt'], \n",
    "                             y=dfg_mean.loc[dfg_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfg_std.loc[dfg_std['level']==l]['mdt'], \n",
    "                             y=dfg_std.loc[dfg_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import downstream.bed_metrics as bm\n",
    "\n",
    "def overlap_with_name_level(overlaps, m, l):\n",
    "    dfo = overlaps[(m, l)].melt(value_name='overlap')\n",
    "    dfo['modification'] = m\n",
    "    dfo['level'] = l\n",
    "    return dfo\n",
    "\n",
    "def show_overlap(df):\n",
    "    levels = sorted(set(df['level']))\n",
    "    overlaps = {}\n",
    "    for m in set(df['modification']):\n",
    "        for l in levels:\n",
    "            print('Processing', m, l)\n",
    "            files = df.loc[np.logical_and(df['modification'] == m, df['level'] == l)]['file']\n",
    "            paths = [Path(f) for f in files]\n",
    "            df_path = f'/tmp/overlap_{m}_{l}.tsv'\n",
    "            overlaps[(m, l)] = bm.load_or_build_metrics_table(paths, paths, Path(df_path), jaccard=False)\n",
    "\n",
    "    dfo = pd.concat([overlap_with_name_level(overlaps, m, l) for (m, l) in overlaps])        \n",
    "    dfo_mean = dfo.groupby(['modification', 'level'])['overlap'].mean().reset_index().sort_values(\n",
    "        by=['modification'])\n",
    "    dfo_std = dfo.groupby(['modification', 'level'])['overlap'].std().reset_index().fillna(0).sort_values(\n",
    "        by=['modification']) \n",
    "    fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Overlap\")))\n",
    "    for l in levels:\n",
    "        fig.add_trace(go.Scatter(x=dfo_mean.loc[dfo_mean['level']==l]['modification'], \n",
    "                                 y=dfo_mean.loc[dfo_mean['level']==l]['overlap'], \n",
    "                                 name=f\"{l} mean\", line_shape='linear'))\n",
    "        fig.add_trace(go.Scatter(x=dfo_std.loc[dfo_std['level']==l]['modification'], \n",
    "                                 y=dfo_std.loc[dfo_std['level']==l]['overlap'], \n",
    "                                 name=f\"{l} std\", line_shape='linear', \n",
    "                                 line=dict(dash='dot')))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me overlaps   \n",
    "geolevels2process = set(['geo'])\n",
    "# show_overlap(dfg.loc[[l in geolevels2process for l in dfg['level']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:48.419134Z",
     "start_time": "2019-03-07T11:38:12.260987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MACS2_FOLDER='/mnt/stripe/bio/raw-data/geo-samples/GSE104284/macs2'\n",
    "MACS2_LEVELS = ['broad_0.05']\n",
    "\n",
    "dfm = pd.DataFrame(columns=['gsm', 'time', 'direction', 'modification', 'replicate', \n",
    "                            'level', 'file', 'peaks', 'length'])\n",
    "for file in tqdm(glob.glob(MACS2_FOLDER + '/*.*Peak')):\n",
    "    if 'gapped' in file or 'Input' in file or not ok(file):\n",
    "        continue\n",
    "    level = next((l for l in MACS2_LEVELS if f'_{l}' in file), None) # \n",
    "    if level:\n",
    "        gsm = re.sub('_.*', '', os.path.basename(file))\n",
    "        if gsm not in geo_gsms:\n",
    "            continue  # Ignore gsms not processed by authors\n",
    "        time = re.sub(f'({gsm}_([^_]*.\\.)?)|(_[0-9a-zA-Z]+_.*)', '', os.path.basename(file))\n",
    "        direction = next((d for d in ['Left', 'Right'] if d in os.path.basename(file)), None)\n",
    "        modification = next((m for m in ['K4me1', 'K4me3', 'K27ac'] if m in os.path.basename(file)), None)        \n",
    "        replicate = re.sub(f'(.*{time}_)|(_{direction}.*)', '', os.path.basename(file))\n",
    "        out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "        if out[0].strip() != '':\n",
    "            peaks, length = out[0].split(' ') \n",
    "        else:\n",
    "            peaks, length = 0, 0\n",
    "        dfm.loc[len(dfm)] = (gsm, time, direction, modification, replicate, f'macs2 {level}', file, peaks, length)\n",
    "\n",
    "dfm['timesrt'] = [\"{:0>3d}\".format(int(re.match('[0-9]+', t)[0]) * 24) if \n",
    "                   t.endswith('d') else \"{:0>3d}\".format(int(re.match('[0-9]+', t)[0])) \n",
    "                  for t in dfm['time'] ]\n",
    "        \n",
    "# Fix types\n",
    "dfm['peaks'] = dfm['peaks'].astype(int)\n",
    "dfm['length'] = dfm['length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfm['mdt'] = dfm['modification'] + '_' + dfm['direction'] + '_' + dfm['timesrt']\n",
    "dfm_mean = dfm.groupby(['mdt', 'level'])['peaks'].mean().reset_index().sort_values(by=['mdt', 'level'])\n",
    "dfm_std = dfm.groupby(['mdt', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['mdt', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfm_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfm_mean.loc[dfm_mean['level']==l]['mdt'], \n",
    "                             y=dfm_mean.loc[dfm_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfm_std.loc[dfm_std['level']==l]['mdt'], \n",
    "                             y=dfm_std.loc[dfm_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me overlaps   \n",
    "macs2levels2process = set(['macs2 broad_0.05'])\n",
    "# show_overlap(dfm.loc[[l in macs2levels2process for l in dfm['level']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SICER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SICER_FOLDER='/mnt/stripe/bio/raw-data/geo-samples/GSE104284/sicer'\n",
    "SICER_LEVELS = ['FDR0.01']\n",
    "\n",
    "dfsc = pd.DataFrame(columns=['gsm', 'time', 'direction', 'modification', 'replicate', \n",
    "                            'level', 'file', 'peaks', 'length'])\n",
    "for file in tqdm(glob.glob(SICER_FOLDER + '/*islands-summary*')):\n",
    "    if 'Input' in file or not ok(file):\n",
    "        continue\n",
    "    level = next((l for l in SICER_LEVELS if l in file), None) # \n",
    "    if level:\n",
    "        gsm = re.sub('_.*', '', os.path.basename(file))\n",
    "        if gsm not in geo_gsms:\n",
    "            continue  # Ignore gsms not processed by authors\n",
    "        time = re.sub(f'({gsm}_([^_]*.\\.)?)|(_[0-9a-zA-Z]+_.*)', '', os.path.basename(file))\n",
    "        direction = next((d for d in ['Left', 'Right'] if d in os.path.basename(file)), None)\n",
    "        modification = next((m for m in ['K4me1', 'K4me3', 'K27ac'] if m in os.path.basename(file)), None)        \n",
    "        replicate = re.sub(f'(.*{time}_)|(_{direction}.*)', '', os.path.basename(file))\n",
    "        out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "        if out[0].strip() != '':\n",
    "            peaks, length = out[0].split(' ') \n",
    "        else:\n",
    "            peaks, length = 0, 0\n",
    "        dfsc.loc[len(dfsc)] = (gsm, time, direction, modification, replicate, f'sicer {level}', file, peaks, length)\n",
    "\n",
    "dfsc['timesrt'] = [\"{:0>3d}\".format(int(re.match('[0-9]+', t)[0]) * 24) if \n",
    "                   t.endswith('d') else \"{:0>3d}\".format(int(re.match('[0-9]+', t)[0])) \n",
    "                  for t in dfsc['time'] ]\n",
    "        \n",
    "# Fix types\n",
    "dfsc['peaks'] = dfsc['peaks'].astype(int)\n",
    "dfsc['length'] = dfsc['length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsc['mdt'] = dfsc['modification'] + '_' + dfsc['direction'] + '_' + dfsc['timesrt']\n",
    "dfsc_mean = dfsc.groupby(['mdt', 'level'])['peaks'].mean().reset_index().sort_values(by=['mdt', 'level'])\n",
    "dfsc_std = dfsc.groupby(['mdt', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['mdt', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfsc_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfsc_mean.loc[dfsc_mean['level']==l]['mdt'], \n",
    "                             y=dfsc_mean.loc[dfsc_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfsc_std.loc[dfsc_std['level']==l]['mdt'], \n",
    "                             y=dfsc_std.loc[dfsc_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me overlaps   \n",
    "sicerlevels2process = set(['sicer FDR0.01'])\n",
    "# show_overlap(dfsc.loc[[l in sicerlevels2process for l in dfsc['level']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAN automated markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# # Bash commands to create markup based on consensus\n",
    "# DIR=/mnt/stripe/bio/raw-data/geo-samples/GSE104284\n",
    "# T=$'\\t'; \n",
    "\n",
    "# for M in K4me1 K4me3 K27ac; do\n",
    "#     echo \"Processing $M\"\n",
    "#     OUT=${DIR}/intersect_${M}.tsv;\n",
    "\n",
    "#     printf %s \"chr${T}start${T}end\" > ${OUT}; \n",
    "#     FILES=(); \n",
    "#     for F in $(find ${DIR}/macs2/ -name \"*${M}*.broadPeak\"); do \n",
    "#         FILES+=(\"$F\"); \n",
    "#         printf %s \"${T}${F}\" >> ${OUT}; \n",
    "#     done; \n",
    "#     echo >> ${OUT};\n",
    "#     bedtools multiinter -i \"${FILES[@]}\" |\\\n",
    "#         bedtools merge -c $(seq -s, 6 1 $((${#FILES[@]} + 5))) -o max |\\\n",
    "#         awk '{if (NR > 1) printf(\"\\n\"); printf(\"%s\\t%s\\t%s\", $1, $2, $3); for (i=4; i<=NF; i++) printf(\"\\t%d\", int($i)); }' >> ${OUT};\n",
    "\n",
    "#     # Find out regions confirmed by at least 50% of files\n",
    "#     CONS=$((${#FILES[@]}/2))\n",
    "#     cat ${OUT} | awk -v OFS='\\t' CONS=${CONS} 'sum=0; for (i=4; i<=NF; i++){sum+= $i}; if (sum>=CONS){print($1,$2,$3)}' > ${DIR}/intersect_all_${M}.bed\n",
    "\n",
    "#     # Find any of the peaks to get scores\n",
    "#     F=$(find ${DIR}/macs2/ -name \"*${M}*.broadPeak\" | head -n 1);\n",
    "#     bedtools intersect -a ${F} -b ${DIR}/intersect_all_${M}.bed -wa > ${DIR}/intersect_all_${M}.broadPeak\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample number of consensus peak with p-value stratification\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# wdir = '/mnt/stripe/bio/raw-data/geo-samples/GSE104284'\n",
    "# for m in ['K4me1', 'K4me3', 'K27ac']:\n",
    "#     print('Processing', m)\n",
    "#     idf = pd.read_csv(f'{wdir}/intersect_all_{m}.broadPeak',\n",
    "#                       names=['chr', 'start', 'end', 'name', 'score', 'strand', 'summitfc', 'mlogp', 'mlogq', 'summit'], \n",
    "#                       sep='\\t')\n",
    "#     idf.sort_values(by=['mlogq'], ascending=False, inplace=True)\n",
    "\n",
    "#     markup_size = 2000\n",
    "#     peaks_file = f'{wdir}/peaks_{m}_{markup_size}.bed'\n",
    "#     step = int(len(idf) / markup_size)\n",
    "#     markup_df = idf.loc[[i % step == 0 for i in range(len(idf))]]\n",
    "#     shuffle(markup_df[['chr', 'start', 'end']]).to_csv(peaks_file, sep='\\t', header=None, index=False)\n",
    "#     print(f'Saved {markup_size} peaks stratified by p-value to {peaks_file}')\n",
    "\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# DIR=/mnt/stripe/bio/raw-data/geo-samples/GSE104284\n",
    "\n",
    "# for M in K4me1 K4me3 K27ac; do\n",
    "#     echo \"Processing $M\"\n",
    "\n",
    "#     # Total 2000 peaks 1000,500,500\n",
    "#     # peaks\n",
    "#     head -n 1000 ${DIR}/peaks_${M}_2000.bed | while read -r LINE; do \\\n",
    "#         echo \"$LINE\" | awk -v OFS='\\t' '{print $1,$2,$3,\"peaks\"}'; \\\n",
    "#     done > ${DIR}/${M}_labels.bed;\n",
    "\n",
    "#     # peakStart\n",
    "#     head -n 1500 ${DIR}/peaks_${M}_2000.bed | tail -n 500 | while read -r LINE; do \\\n",
    "#         echo \"$LINE\" | awk '{ printf(\"%s\\t%d\\t%d\\t%s\\n\", $1,$2-1000,($2+$3)/2 - 1,\"peakStart\")}'; \\\n",
    "#     done >> ${DIR}/${M}_labels.bed;\n",
    "\n",
    "#     # peakEnd\n",
    "#     head -n 2000 ${DIR}/peaks_${M}_2000.bed | tail -n 500 | while read -r LINE; do \\\n",
    "#         echo \"$LINE\" | awk '{printf(\"%s\\t%d\\t%d\\t%s\\n\", $1,($2+$3)/2 + 1,$3+1000,\"peakEnd\")}'; \\\n",
    "#     done >> ${DIR}/${M}_labels.bed;\n",
    "\n",
    "#     # extended markup\n",
    "#     cat ${DIR}/${M}_labels.bed | while read -r LINE; do \\\n",
    "#         echo \"$LINE\" | awk '{print($1,$2-2000,$3+2000)}'; \\\n",
    "#     done > ${DIR}/${M}_labels_ext.bed;\n",
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAN_FOLDER='/mnt/stripe/bio/raw-data/geo-samples/GSE104284/span'\n",
    "# SPAN_LEVELS = ['200_0.01_5', '200_1E-6_5', 'tuned']\n",
    "SPAN_LEVELS = ['tuned']\n",
    "\n",
    "dfs = pd.DataFrame(columns=['gsm', 'time', 'direction', 'modification', 'replicate', \n",
    "                            'level', 'file', 'peaks', 'length'])\n",
    "for file in tqdm(glob.glob(SPAN_FOLDER + '/*.peak')):\n",
    "    if 'gapped' in file or 'Input' in file or not ok(file):\n",
    "        continue\n",
    "    level = next((l for l in SPAN_LEVELS if f'_{l}' in file), None) # \n",
    "    if level:\n",
    "        gsm = re.sub('_.*', '', os.path.basename(file))\n",
    "        if gsm not in geo_gsms:\n",
    "            continue  # Ignore gsms not processed by authors\n",
    "        time = re.sub(f'({gsm}_([^_]*.\\.)?)|(_[0-9a-zA-Z]+_.*)', '', os.path.basename(file))\n",
    "        direction = next((d for d in ['Left', 'Right'] if d in os.path.basename(file)), None)\n",
    "        modification = next((m for m in ['K4me1', 'K4me3', 'K27ac'] if m in os.path.basename(file)), None)        \n",
    "        replicate = re.sub(f'(.*{time}_)|(_{direction}.*)', '', os.path.basename(file))\n",
    "        out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "        if out[0].strip() != '':\n",
    "            peaks, length = out[0].split(' ') \n",
    "        else:\n",
    "            peaks, length = 0, 0\n",
    "        dfs.loc[len(dfs)] = (gsm, time, direction, modification, replicate, f'span {level}', file, peaks, length)\n",
    "\n",
    "dfs['timesrt'] = [\"{:0>3d}\".format(int(re.match('[0-9]+', t)[0]) * 24) if \n",
    "                   t.endswith('d') else \"{:0>3d}\".format(int(re.match('[0-9]+', t)[0])) \n",
    "                  for t in dfs['time'] ]\n",
    "        \n",
    "# Fix types\n",
    "dfs['peaks'] = dfs['peaks'].astype(int)\n",
    "dfs['length'] = dfs['length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['mdt'] = dfs['modification'] + '_' + dfs['direction'] + '_' + dfs['timesrt']\n",
    "dfs_mean = dfs.groupby(['mdt', 'level'])['peaks'].mean().reset_index().sort_values(by=['mdt', 'level'])\n",
    "dfs_std = dfs.groupby(['mdt', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['mdt', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfs_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfs_mean.loc[dfs_mean['level']==l]['mdt'], \n",
    "                             y=dfs_mean.loc[dfs_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfs_std.loc[dfs_std['level']==l]['mdt'], \n",
    "                             y=dfs_std.loc[dfs_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show me overlaps   \n",
    "spanlevels2process = set(['span tuned'])\n",
    "# show_overlap(dfs.loc[[l in spanlevels2process for l in dfs['level']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.concat([dfg.loc[[l in geolevels2process for l in dfg['level']]],\n",
    "                 dfm.loc[[l in macs2levels2process for l in dfm['level']]],\n",
    "                 dfsc.loc[[l in sicerlevels2process for l in dfsc['level']]],\n",
    "                 dfs.loc[[l in spanlevels2process for l in dfs['level']]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['mdt'] = dfa['modification'] + '_' + dfa['direction'] + '_' + dfa['timesrt']\n",
    "dfa_mean = dfa.groupby(['mdt', 'level'])['peaks'].mean().reset_index().sort_values(by=['mdt', 'level'])\n",
    "dfa_std = dfa.groupby(['mdt', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['mdt', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfa_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfa_mean.loc[dfa_mean['level']==l]['mdt'], \n",
    "                             y=dfa_mean.loc[dfa_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfa_std.loc[dfa_std['level']==l]['mdt'], \n",
    "                             y=dfa_std.loc[dfa_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_mean = dfa.groupby(['modification', 'level'])['peaks'].mean().reset_index().sort_values(\n",
    "    by=['modification', 'level'])\n",
    "dfa_std = dfa.groupby(['modification', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(\n",
    "    by=['modification', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfa_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfa_mean.loc[dfa_mean['level']==l]['modification'], \n",
    "                             y=dfa_mean.loc[dfa_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfa_std.loc[dfa_std['level']==l]['modification'], \n",
    "                             y=dfa_std.loc[dfa_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['avg_length'] = dfa['length'] / dfa['peaks']\n",
    "dfa.loc[~np.isfinite(dfa[\"avg_length\"]), \"avg_length\"] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_cells(df, cid, value, description):\n",
    "    cids = sorted(set(df[cid]))\n",
    "    axs = {}\n",
    "    total = len(cids) * 3\n",
    "    fig = plt.figure(figsize=(int(total * .75), 4))\n",
    "    offset = 0\n",
    "    for m in ['K27ac', 'K4me1', 'K4me3']:\n",
    "        data = df.loc[df['modification'] == m].sort_values(by=[cid])\n",
    "        xlabels = []\n",
    "        for c in data[cid]:\n",
    "            if c not in xlabels:\n",
    "                xlabels.append(c)\n",
    "        w = len(cids)\n",
    "        ax = plt.subplot2grid((1, total), (0, offset), colspan=w)\n",
    "\n",
    "        sns.barplot(data=data, \n",
    "                     x=cid, y=value,\n",
    "                     ci=\"sd\", capsize=.2, errwidth=2,\n",
    "                     edgecolor=\"black\",\n",
    "                     ax = ax)\n",
    "\n",
    "        sns.swarmplot(data=data,\n",
    "                      x=cid, y=value,\n",
    "                      size=1,\n",
    "                      color=\"black\",\n",
    "                      alpha=0.5,\n",
    "                      ax = ax)\n",
    "        ax.legend().set_visible(False)\n",
    "        axs[ax] = plt.ylim()\n",
    "        if offset > 0:\n",
    "            ax.get_yaxis().set_ticklabels([])\n",
    "            ax.set_ylabel('')\n",
    "        else:\n",
    "            ax.set_ylabel(description)\n",
    "        \n",
    "        offset += w\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_title(m)\n",
    "        plt.xticks(range(0, len(xlabels)), xlabels, rotation=45)\n",
    "            \n",
    "    ymin = np.min([v[0] for v in axs.values()])\n",
    "    ymax = np.max([v[1] for v in axs.values()])\n",
    " \n",
    "    for ax in axs.keys():\n",
    "        ax.set_ylim(bottom = ymin, top = ymax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_cells(dfa, 'level', 'peaks', 'Peaks')\n",
    "plt.show()\n",
    "plot_data_cells(dfa, 'level', 'avg_length', 'Average peak length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['ld'] = dfa['level'] + '_' + dfa['direction']\n",
    "plot_data_cells(dfa, 'ld', 'peaks', 'Peaks')\n",
    "plt.show()\n",
    "plot_data_cells(dfa, 'ld', 'avg_length', 'Average peak length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_overlap(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_overlap(df):\n",
    "    # Compute overlaps\n",
    "    dft = pd.DataFrame(columns=['id', 'modification', 'level', 'direction', 'overlap'])\n",
    "    levels = sorted(set(df['level']))\n",
    "    for m in ['K27ac', 'K4me1', 'K4me3']:\n",
    "        for l in levels:\n",
    "            for d in ['Left', 'Right']:\n",
    "                paths = [Path(f) for f in df.loc[np.logical_and(df['modification']==m, \n",
    "                    np.logical_and(df['level']==l, df['direction']==d))]['file']]\n",
    "                df_path = f'/tmp/overlap_{m}_{l}_{d}.tsv'\n",
    "                mt = bm.load_or_build_metrics_table(paths, paths, Path(df_path),\n",
    "                                                    jaccard=False,\n",
    "                                                    threads=30)\n",
    "                for row in mt.index:\n",
    "                    for col in mt.columns:\n",
    "                        overlap = mt.loc[row][col]\n",
    "                        dft.loc[len(dft)] = (f'{row}@{col}', m, l, d, overlap)\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = compute_overlap(dfa)\n",
    "df_overlap['ld'] = df_overlap['level'] + '_' + df_overlap['direction']\n",
    "plot_data_cells(df_overlap, 'ld', 'overlap', 'Overlaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
