{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GSE53643 - Replicated H3K4me2 consistency, SPAN automarkup\n",
    "\n",
    "Logbook: https://docs.google.com/document/d/1VGH4fA20LbhGGKWvBg28E7G1JBm1rLlmCEtD2X239Eg/edit#heading=h.44kd47qfiiva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:12.254230Z",
     "start_time": "2019-03-07T11:38:04.952806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os, re\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import subprocess, tempfile\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACS2\n",
    "\n",
    "For different Q values:\n",
    "\n",
    "```\n",
    "# Narrow\n",
    "snakemake all_macs2_results --use-conda --cores 28  --config work_dir=/mnt/stripe/bio/raw-data/geo-samples/GSE53643 fastq_dir=/mnt/stripe/bio/raw-data/geo-samples/GSE53643/fastq genome=hg38 macs2_mode=narrow macs2_suffix=\"q0.01\" macs2_params=\"-q 0.01\"\n",
    "\n",
    "# 50k strongest peaks\n",
    "for F in *peaks.narrowPeak; do echo $F; cat $F | sort -k9,9nr | head -n 50000 | sort -k1,1 -k2,2n > ${F/.narrowPeak/_50k.narrowPeak}; done\n",
    "\n",
    "# Broad\n",
    "snakemake all_macs2_results --use-conda --cores 28  --config work_dir=/mnt/stripe/bio/raw-data/geo-samples/GSE53643 fastq_dir=/mnt/stripe/bio/raw-data/geo-samples/GSE53643/fastq genome=hg38 macs2_mode=broad macs2_suffix=\"broad_0.1\" macs2_params=\"--broad --broad-cutoff 0.1\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:48.419134Z",
     "start_time": "2019-03-07T11:38:12.260987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MACS2_FOLDER='/mnt/stripe/bio/raw-data/geo-samples/GSE53643/macs2'\n",
    "MACS2_LEVELS = ['50k', 'q0.05', 'q0.01', 'q1e-4', 'q1e-6', \n",
    "                'broad_0.1', 'broad_0.05', 'broad_0.01', 'broad_1e-4', 'broad_1e-6']\n",
    "\n",
    "dfm = pd.DataFrame(columns=['gsm', 'name', 'replicate', 'level', 'file', 'peaks', 'length'])\n",
    "for file in tqdm(glob.glob(MACS2_FOLDER + '/*.*Peak')):\n",
    "    level = next((l for l in MACS2_LEVELS if f'_{l}' in file), None) # \n",
    "    if level:\n",
    "        gsm = re.sub('_H3K4me2.*', '', os.path.basename(file))\n",
    "        name = re.sub('(GSM[0-9]+_)|(-rep[0-9].*)', '', os.path.basename(file))\n",
    "        replicate = re.match('rep[0-9]+', os.path.basename(file))\n",
    "        out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "        peaks, length = out[0].split(' ')\n",
    "        dfm.loc[len(dfm)] = (gsm, name, replicate, f'macs2 {level}', file, peaks, length)\n",
    "\n",
    "# Fix types\n",
    "dfm['peaks'] = dfm['peaks'].astype(int)\n",
    "dfm['length'] = dfm['length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfm_mean = dfm.groupby(['name', 'level'])['peaks'].mean().reset_index().sort_values(by=['name', 'level'])\n",
    "dfm_std = dfm.groupby(['name', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['name', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfm_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfm_mean.loc[dfm_mean['level']==l]['name'], \n",
    "                             y=dfm_mean.loc[dfm_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfm_std.loc[dfm_std['level']==l]['name'], \n",
    "                             y=dfm_std.loc[dfm_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:49.749046Z",
     "start_time": "2019-03-07T11:38:49.511080Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import downstream.bed_metrics as bm\n",
    "\n",
    "def overlap_with_name_level(overlaps, n, l):\n",
    "    dfo = overlaps[(n, l)].melt(value_name='overlap')\n",
    "    dfo['name'] = n\n",
    "    dfo['level'] = l\n",
    "    return dfo\n",
    "\n",
    "def show_overlap(df):\n",
    "    levels = sorted(set(df['level']))\n",
    "    overlaps = {}\n",
    "    for n in set(df['name']):\n",
    "        for l in levels:\n",
    "            print('Processing', n, l)\n",
    "            files = df.loc[np.logical_and(df['name'] == n, df['level'] == l)]['file']\n",
    "            paths = [Path(f) for f in files]\n",
    "            df_path = f'/tmp/overlap_{n}_{l}.tsv'\n",
    "            overlaps[(n, l)] = bm.load_or_build_metrics_table(paths, paths, Path(df_path), jaccard=False)\n",
    "\n",
    "    dfo = pd.concat([overlap_with_name_level(overlaps, n, l) for (n, l) in overlaps])        \n",
    "    dfo_mean = dfo.groupby(['name', 'level'])['overlap'].mean().reset_index().sort_values(by=['name'])\n",
    "    dfo_std = dfo.groupby(['name', 'level'])['overlap'].std().reset_index().fillna(0).sort_values(by=['name']) \n",
    "    fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Overlap\")))\n",
    "    for l in levels:\n",
    "        fig.add_trace(go.Scatter(x=dfo_mean.loc[dfo_mean['level']==l]['name'], \n",
    "                                 y=dfo_mean.loc[dfo_mean['level']==l]['overlap'], \n",
    "                                 name=f\"{l} mean\", line_shape='linear'))\n",
    "        fig.add_trace(go.Scatter(x=dfo_std.loc[dfo_std['level']==l]['name'], \n",
    "                                 y=dfo_std.loc[dfo_std['level']==l]['overlap'], \n",
    "                                 name=f\"{l} std\", line_shape='linear', \n",
    "                                 line=dict(dash='dot')))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T11:38:50.552428Z",
     "start_time": "2019-03-07T11:38:49.754389Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "macs2levels2process = set(['macs2 q0.05', 'macs2 q0.01', 'macs2 q1e-4',\n",
    "                          'macs2 broad_0.05', 'macs2 broad_0.01', 'macs2 broad_1e-4'])\n",
    "show_overlap(dfm.loc[[l in macs2levels2process for l in dfm['level']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAN automated markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Bash commands to create markup by Immgen\n",
    "DIR=/mnt/stripe/bio/raw-data/geo-samples/GSE53643\n",
    "OUT=${DIR}/intersect.tsv;\n",
    "T=$'\\t'; \n",
    "printf %s \"chr${T}start${T}end\" > ${OUT}; \n",
    "FILES=(); \n",
    "for F in $(find ${DIR}/macs2/ -name \"*.narrowPeak\"); do \n",
    "    FILES+=(\"$F\"); \n",
    "    printf %s \"${T}${F}\" >> ${OUT}; \n",
    "done; \n",
    "echo >> ${OUT};\n",
    "bedtools multiinter -i \"${FILES[@]}\" |\\\n",
    "    bedtools merge -c $(seq -s, 6 1 $((${#FILES[@]} + 5))) -o max |\\\n",
    "    awk '{if (NR > 1) printf(\"\\n\"); printf(\"%s\\t%s\\t%s\", $1, $2, $3); for (i=4; i<=NF; i++) printf(\"\\t%d\", int($i)); }' >> ${OUT};\n",
    "\n",
    "# Find out regions where all the peaks present\n",
    "ALL=\"\"; \n",
    "for F in $(seq 1 1 ${#FILES[@]}); do \n",
    "    ALL=\"${ALL}${T}1\"; \n",
    "done; \n",
    "cat ${OUT} | grep \"${ALL}\" | awk -v OFS='\\t' '{print $1,$2,$3}' > ${DIR}/intersect_all.bed\n",
    "\n",
    "# Find any of the peaks to get scores\n",
    "F=$(find ${DIR}/macs2/ -name \"*.narrowPeak\" | head -n 1);\n",
    "bedtools intersect -a ${F} -b ${DIR}/intersect_all.bed -wa > ${DIR}/intersect_all.narrowPeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "idf = pd.read_csv('/mnt/stripe/bio/raw-data/geo-samples/GSE53643/intersect_all.narrowPeak',\n",
    "                  names=['chr', 'start', 'end', 'name', 'score', 'strand', 'summitfc', 'mlogp', 'mlogq', 'summit'], \n",
    "                  sep='\\t')\n",
    "idf.sort_values(by=['mlogq'], ascending=False, inplace=True)\n",
    "\n",
    "markup_size = 2000\n",
    "peaks_file = f'/mnt/stripe/bio/raw-data/geo-samples/GSE53643/peaks_{markup_size}.bed'\n",
    "step = int(len(idf) / markup_size)\n",
    "markup_df = idf.loc[[i % step == 0 for i in range(len(idf))]]\n",
    "shuffle(markup_df[['chr', 'start', 'end']]).to_csv(peaks_file, sep='\\t', header=None, index=False)\n",
    "print(f'Saved {markup_size} peaks stratified by p-value to {peaks_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DIR=/mnt/stripe/bio/raw-data/geo-samples/GSE53643\n",
    "\n",
    "# Total 2000 peaks 1000,500,500\n",
    "# peaks\n",
    "head -n 1000 ${DIR}/peaks_2000.bed | while read -r LINE; do \\\n",
    "    echo \"$LINE\" | awk -v OFS='\\t' '{print $1,$2,$3,\"peaks\"}'; \\\n",
    "done > ${DIR}/markup.bed\n",
    "\n",
    "# peakStart\n",
    "head -n 1500 ${DIR}/peaks_2000.bed | tail -n 500 | while read -r LINE; do \\\n",
    "    echo \"$LINE\" | awk '{ printf(\"%s\\t%d\\t%d\\t%s\\n\", $1,$2-1000,($2+$3)/2 - 1,\"peakStart\")}'; \\\n",
    "done >> ${DIR}/markup.bed\n",
    "\n",
    "# peakEnd\n",
    "head -n 2000 ${DIR}/peaks_2000.bed | tail -n 500 | while read -r LINE; do \\\n",
    "    echo \"$LINE\" | awk '{printf(\"%s\\t%d\\t%d\\t%s\\n\", $1,($2+$3)/2 + 1,$3+1000,\"peakEnd\")}'; \\\n",
    "done >> ${DIR}/markup.bed\n",
    "\n",
    "# extended markup\n",
    "cat ${DIR}/markup.bed | while read -r LINE; do \\\n",
    "    echo \"$LINE\" | awk '{print($1,$2-2000,$3+2000)}'; \\\n",
    "done > ${DIR}/markup_ext.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPAN tuning\n",
    "```\n",
    "cd /mnt/stripe/shpynov/chipseq-smk-pipeline\n",
    "snakemake all_span_tuned --use-conda --cores 28  --config work_dir=/mnt/stripe/bio/raw-data/geo-samples/GSE53643 fastq_dir=/mnt/stripe/bio/raw-data/geo-samples/GSE53643/fastq genome=hg38 span_bin=200 span_markup=/mnt/stripe/bio/raw-data/geo-samples/GSE53643/markup.bed -n\n",
    "\n",
    "## Rename tuned\n",
    "mkdir /mnt/stripe/bio/raw-data/geo-samples/GSE53643/span_tuned\n",
    "for F in /mnt/stripe/bio/raw-data/geo-samples/GSE53643/span/*tuned.peak; do echo $F; P=$(head\n",
    "-n 1 $F | sed -E 's/(^.*_200_)|(_1\\t.*$)//g'); cp -f $F \"/mnt/stripe/bio/raw-data/geo-samples/GSE53643/span_tuned/$(echo $F | sed \"s/tuned/$P/g\" | sed 's#.*/##g')\"; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAN_FOLDER='/mnt/stripe/bio/raw-data/geo-samples/GSE53643/span'\n",
    "SPAN_LEVELS = ['100_0.01_0', '100_1e-06_0', '100_tuned', '200_0.01_0', '200_1e-06_5', '200_tuned']\n",
    "\n",
    "dfs = pd.DataFrame(columns=['gsm', 'name', 'replicate', 'level', 'file', 'peaks', 'length'])\n",
    "for file in tqdm(glob.glob(SPAN_FOLDER + '/*.peak')):\n",
    "    level = next((l for l in SPAN_LEVELS if f'_{l}.' in file), None) # \n",
    "    if level:\n",
    "        gsm = re.sub('_H3K4me2.*', '', os.path.basename(file))\n",
    "        name = re.sub('(GSM[0-9]+_)|(-rep[0-9].*)', '', os.path.basename(file))\n",
    "        replicate = re.match('rep[0-9]+', os.path.basename(file))\n",
    "        out = ! awk '{{N+=1;L+=($$3-$$2)}} END{{print(N,L)}}' {file}\n",
    "        peaks, length = out[0].split(' ')\n",
    "        dfs.loc[len(dfs)] = (gsm, name, replicate, f'span {level}', file, peaks, length)\n",
    "\n",
    "# Fix types\n",
    "dfs['peaks'] = dfs['peaks'].astype(int)\n",
    "dfs['length'] = dfs['length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "dfs_mean = dfs.groupby(['name', 'level'])['peaks'].mean().reset_index().sort_values(by=['name', 'level'])\n",
    "dfs_std = dfs.groupby(['name', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['name', 'level'])\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfs_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfs_mean.loc[dfs_mean['level']==l]['name'], \n",
    "                             y=dfs_mean.loc[dfs_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfs_std.loc[dfs_std['level']==l]['name'], \n",
    "                             y=dfs_std.loc[dfs_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spanlevels2process = set(['span 200_1e-06_5', 'span 200_tuned', 'span 100_1e-06_0', 'span 100_tuned'])\n",
    "show_overlap(dfs.loc[[l in spanlevels2process for l in dfs['level']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.concat([dfm.loc[[l in macs2levels2process for l in dfm['level']]], \n",
    "                 dfs.loc[[l in spanlevels2process for l in dfs['level']]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_mean = dfa.groupby(['name', 'level'])['peaks'].mean().reset_index().sort_values(by=['name', 'level'])\n",
    "dfa_std = dfa.groupby(['name', 'level'])['peaks'].std().reset_index().fillna(0).sort_values(by=['name', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=\"Peaks\")))\n",
    "for l in sorted(set(dfa_mean['level'])):\n",
    "    fig.add_trace(go.Scatter(x=dfa_mean.loc[dfa_mean['level']==l]['name'], \n",
    "                             y=dfa_mean.loc[dfa_mean['level']==l]['peaks'], \n",
    "                             name=f\"{l} mean\", line_shape='linear'))\n",
    "    fig.add_trace(go.Scatter(x=dfa_std.loc[dfa_std['level']==l]['name'], \n",
    "                             y=dfa_std.loc[dfa_std['level']==l]['peaks'], \n",
    "                             name=f\"{l} std\", line_shape='linear', \n",
    "                             line=dict(dash='dot')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_overlap(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['avg_length'] = dfa['length'] / dfa['peaks']\n",
    "dfa.loc[~np.isfinite(dfa[\"avg_length\"]), \"avg_length\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, value):\n",
    "    levels = sorted(set(df['level']))\n",
    "    fig = plt.figure(figsize=(len(levels), 5))\n",
    "    ax = plt.gca()\n",
    "    sns.barplot(data=df, \n",
    "                 x=\"level\", y=value,\n",
    "                 ci=\"sd\", capsize=.2, errwidth=2,\n",
    "                 edgecolor=\"black\",\n",
    "                 ax = ax)\n",
    "\n",
    "    sns.swarmplot(data=df,\n",
    "                  x=\"level\", y=value,\n",
    "                  color=\"black\",\n",
    "                  size=2,\n",
    "                  alpha=0.5,\n",
    "                  ax = ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(dfa, 'peaks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(dfa, 'avg_length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups analysis CC4Naive / CC4Neg / Naive T-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell(sample):\n",
    "    for v in ['CCR4Neg', 'CCR4pos', 'Naive']:\n",
    "        if v in sample:\n",
    "            return v\n",
    "    raise Exception(f'Unknown sample cell {sample}')\n",
    "\n",
    "dfa['cell'] = list(map(cell, dfa['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_cells(df, value, description):\n",
    "    cells = sorted(set(df['cell']))\n",
    "    levels = sorted(set(df['level']))\n",
    "    axs = {}\n",
    "    total = len(levels) * len(cells)\n",
    "    fig = plt.figure(figsize=(int(total * .75), 4))\n",
    "    offset = 0\n",
    "    for c in cells:\n",
    "        data = df.loc[df['cell'] == c].sort_values(by=['level'])\n",
    "        xlabels = []\n",
    "        for l in data['level']:\n",
    "            if l not in xlabels:\n",
    "                xlabels.append(l)\n",
    "        w = len(levels)\n",
    "        ax = plt.subplot2grid((1, total), (0, offset), colspan=w)\n",
    "\n",
    "        sns.barplot(data=data, \n",
    "                     x=\"level\", y=value,\n",
    "                     ci=\"sd\", capsize=.2, errwidth=2,\n",
    "                     edgecolor=\"black\",\n",
    "                     ax = ax)\n",
    "\n",
    "        sns.swarmplot(data=data,\n",
    "                      x=\"level\", y=value,\n",
    "                      size=1,\n",
    "                      color=\"black\",\n",
    "                      alpha=0.5,\n",
    "                      ax = ax)\n",
    "        ax.legend().set_visible(False)\n",
    "        axs[ax] = plt.ylim()\n",
    "        if offset > 0:\n",
    "            ax.get_yaxis().set_ticklabels([])\n",
    "            ax.set_ylabel('')\n",
    "        else:\n",
    "            ax.set_ylabel(description)\n",
    "        \n",
    "        offset += w\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_title(c)\n",
    "        plt.xticks(range(0, len(xlabels)), xlabels, rotation=45)\n",
    "            \n",
    "    ymin = np.min([v[0] for v in axs.values()])\n",
    "    ymax = np.max([v[1] for v in axs.values()])\n",
    " \n",
    "    for ax in axs.keys():\n",
    "        ax.set_ylim(bottom = ymin, top = ymax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_cells(dfa, 'peaks', 'Peaks')\n",
    "plt.show()\n",
    "plot_data_cells(dfa, 'avg_length', 'Average peak length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_overlap(df):\n",
    "    # Compute overlaps\n",
    "    dft = pd.DataFrame(columns=['id', 'cell', 'level', 'overlap'])\n",
    "    cells = sorted(set(df['cell']))\n",
    "    levels = sorted(set(df['level']))\n",
    "    for c in cells:\n",
    "        for l in levels:\n",
    "            paths = [Path(f) for f in df.loc[np.logical_and(df['cell']==c, df['level']==l)]['file']]\n",
    "            df_path = f'/tmp/overlap_{c}_{l}.tsv'\n",
    "            mt = bm.load_or_build_metrics_table(paths, paths, Path(df_path),\n",
    "                                                jaccard=False,\n",
    "                                                threads=30)\n",
    "            for row in mt.index:\n",
    "                for col in mt.columns:\n",
    "                    overlap = mt.loc[row][col]\n",
    "                    dft.loc[len(dft)] = (f'{row}@{col}', c, l, overlap)\n",
    "    return dft\n",
    "\n",
    "df_overlap = compute_overlap(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_cells(df_overlap, 'overlap', 'Overlaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
